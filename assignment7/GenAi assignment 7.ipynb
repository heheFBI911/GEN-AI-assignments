{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPVPVrT8SO9m5SLoPPeFRqG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdJdkHbcTfAp","executionInfo":{"status":"ok","timestamp":1741513943382,"user_tz":-330,"elapsed":125391,"user":{"displayName":"12_swapnil_darphale","userId":"00951848598189379902"}},"outputId":"83d0ebc0-f972-4cd9-b5bc-fa74c9fc6dfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n","Collecting ftfy\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n","Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ftfy\n","Successfully installed ftfy-6.3.1\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-yrlrtne6\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-yrlrtne6\n","  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.5.1+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.20.1+cu124)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=fadc559e90cfb10bc436430377c429cccf1e6731b899beefd11a5752225bed8d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2yqtjrng/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n","Successfully built clip\n","Installing collected packages: clip\n","Successfully installed clip-1.0\n"]}],"source":["!pip install torch torchvision\n","!pip install Pillow\n","!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","source":["import torch\n","import clip\n","from PIL import Image\n","import requests\n","from io import BytesIO"],"metadata":{"id":"sNa6ySZTUh-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_caption_from_file(image_path, candidate_file, model_name=\"ViT-B/32\"):\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    # Load the CLIP model and its preprocessing function.\n","    model, preprocess = clip.load(model_name, device=device)\n","\n","    # Load and preprocess the image.\n","    image = Image.open(image_path)\n","    image_input = preprocess(image).unsqueeze(0).to(device)\n","\n","    # Read candidate captions from file (one caption per line).\n","    with open(candidate_file, \"r\", encoding=\"utf-8\") as f:\n","        candidate_captions = [line.strip() for line in f if line.strip()]\n","\n","    # Tokenize the candidate captions.\n","    text_inputs = clip.tokenize(candidate_captions).to(device)\n","\n","    # Compute the image and text features.\n","    with torch.no_grad():\n","        image_features = model.encode_image(image_input)\n","        text_features = model.encode_text(text_inputs)\n","\n","    # Normalize the features to get cosine similarity as the dot product.\n","    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n","    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n","\n","    # Compute cosine similarity between the image and each candidate caption.\n","    similarities = (image_features @ text_features.T).squeeze(0)\n","\n","    # Select the caption with the highest similarity.\n","    best_caption_index = torch.argmax(similarities).item()\n","    best_caption = candidate_captions[best_caption_index]\n","\n","    return best_caption"],"metadata":{"id":"0a4cuP6zUpYQ","executionInfo":{"status":"ok","timestamp":1741525721866,"user_tz":-330,"elapsed":33,"user":{"displayName":"12_swapnil_darphale","userId":"00951848598189379902"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def chat():\n","    image_url = input(\"Please enter the image URL: \").strip()\n","    try:\n","        response = requests.get(image_url)\n","        response.raise_for_status()\n","        image_data = BytesIO(response.content)\n","        return image_data\n","    except Exception as e:\n","        print(\"Failed to retrieve the image. Error:\", e)\n","        exit(1)"],"metadata":{"id":"QQA3zBWIBcek","executionInfo":{"status":"ok","timestamp":1741525734311,"user_tz":-330,"elapsed":39,"user":{"displayName":"12_swapnil_darphale","userId":"00951848598189379902"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install clip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HB0mfWtfO-uk","executionInfo":{"status":"ok","timestamp":1741579688152,"user_tz":-330,"elapsed":6741,"user":{"displayName":"12_swapnil_darphale","userId":"00951848598189379902"}},"outputId":"6817e0cb-9e83-4c2a-bca9-5c064a48d725"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting clip\n","  Downloading clip-0.2.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=6988 sha256=799fd197a6d67af89cdc6783c88f9c3e0fe02b9953b0e7567ebd35987192a52f\n","  Stored in directory: /root/.cache/pip/wheels/ab/a5/e8/c9fa20742edbccf2702dae8ee62053e6c460e961d45967b49c\n","Successfully built clip\n","Installing collected packages: clip\n","Successfully installed clip-0.2.0\n"]}]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","  while(True):\n","    image_source = chat()\n","    candidate_file = \"candidate_captions.txt\"\n","\n","    caption = get_caption_from_file(image_source, candidate_file)\n","    print(\"Selected Caption:\", caption)\n","\n","    print(\"Would you like to continue? (y/n)\")\n","    choice = input().strip().lower()\n","    if choice != 'y':\n","        print(\"Bye ðŸ‘‹\")\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"NL11EAF7PZ_z","executionInfo":{"status":"error","timestamp":1741579726499,"user_tz":-330,"elapsed":54,"user":{"displayName":"12_swapnil_darphale","userId":"00951848598189379902"}},"outputId":"c522b06c-3ce6-4238-ac2a-18660006dc91"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'chat' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-7ea738700fea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimage_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcandidate_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"candidate_captions.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'chat' is not defined"]}]},{"cell_type":"code","source":["import torch\n","import clip\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","\n","def get_caption_from_file(image_path, candidate_file, model_name=\"ViT-B/32\"):\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    # Load the CLIP model and its preprocessing function.\n","    model, preprocess = clip.load(model_name, device=device)\n","\n","    # Load and preprocess the image.\n","    image = Image.open(image_path)\n","    image_input = preprocess(image).unsqueeze(0).to(device)\n","\n","    # Read candidate captions from file (one caption per line).\n","    with open(candidate_file, \"r\", encoding=\"utf-8\") as f:\n","        candidate_captions = [line.strip() for line in f if line.strip()]\n","\n","    # Tokenize the candidate captions.\n","    text_inputs = clip.tokenize(candidate_captions).to(device)\n","\n","    # Compute the image and text features.\n","    with torch.no_grad():\n","        image_features = model.encode_image(image_input)\n","        text_features = model.encode_text(text_inputs)\n","\n","    # Normalize the features to get cosine similarity as the dot product.\n","    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n","    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n","\n","    # Compute cosine similarity between the image and each candidate caption.\n","    similarities = (image_features @ text_features.T).squeeze(0)\n","\n","    # Select the caption with the highest similarity.\n","    best_caption_index = torch.argmax(similarities).item()\n","    best_caption = candidate_captions[best_caption_index]\n","\n","    return best_caption\n","\n","if __name__ == \"__main__\":\n","    while True:\n","        image_source = input(\"Enter image path (or URL): \").strip()\n","\n","        if image_source.startswith(\"http\"):\n","            response = requests.get(image_source)\n","            image_source = BytesIO(response.content)\n","\n","        candidate_file = \"candidate_captions.txt\"\n","\n","        try:\n","            caption = get_caption_from_file(image_source, candidate_file)\n","            print(\"Selected Caption:\", caption)\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","\n","        choice = input(\"Would you like to continue? (y/n): \").strip().lower()\n","        if choice != 'y':\n","            print(\"Bye ðŸ‘‹\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqo-DjTBPg6n","executionInfo":{"status":"ok","timestamp":1741579806862,"user_tz":-330,"elapsed":51268,"user":{"displayName":"12_swapnil_darphale","userId":"00951848598189379902"}},"outputId":"a6b02bd2-f585-408f-9360-54cc204ae81f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter image path (or URL): https://images.unsplash.com/photo-1583687534963-565854a3d6d8?fm=jpg&q=60&w=3000&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8NHx8Z2luZ2VyJTIwY2F0fGVufDB8fDB8fHww\n","Error: module 'clip' has no attribute 'load'\n","Would you like to continue? (y/n): y\n","Enter image path (or URL): data:image/webp;base64,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\n","Error: module 'clip' has no attribute 'load'\n","Would you like to continue? (y/n): n\n","Bye ðŸ‘‹\n"]}]}]}